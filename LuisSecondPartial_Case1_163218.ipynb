{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e587e79-ecd9-44b2-8f74-fbdfa5689d17",
   "metadata": {},
   "source": [
    "### **Problem: Emotion Detection in Text**\n",
    "\n",
    "We need to classify emotions in text messages using Bayes' Theorem, based on a set of predefined probabilities for words given emotions and the overall probabilities of emotions themselves.\n",
    "\n",
    "### **Solution Design**\n",
    "**1. Data Preprocessing**\n",
    "\n",
    "We will clean the text input by:\n",
    "\n",
    "* Removing punctuation.\n",
    "* Converting all text to lowercase.\n",
    "* Tokenizing the text into words.\n",
    "\n",
    "**2. Bayesian Algorithm**\n",
    "\n",
    "* Prior Probabilities $P(E)$: The probability of each emotion before seeing the text.\n",
    "* Likelihood $P(W∣E):$ The probability of each word given an emotion.\n",
    "* Posterior Probability $P(E∣W)$: The probability of an emotion given the text message. This is calculated using:\n",
    "$$ P(E∣W) = \\frac{P(W∣E)P(E)}{P(W)} $$\n",
    "where $P(W)$ is calculated by summing over all emotions:\n",
    "\n",
    "$$ P(W) = \\sum{P(W∣E)P(E)} $$\n",
    "\n",
    "**3. Handling Errors**\n",
    "\n",
    "If a word is not found in the database, we assume a low probability for that word in the context of all emotions to avoid zeroing out the results.\n",
    "\n",
    "**4. User Interface**\n",
    "\n",
    "We'll create a simple input mechanism that accepts a text message from the user and outputs the most probable emotion based on Bayesian classification.\n",
    "\n",
    "### **Python Implementation**\n",
    "\n",
    "Python implementation using the above logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534afd72-d9f4-4bcf-8d6a-bbf599973a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Example data\n",
    "emotions = ['happy', 'sad', 'angry']\n",
    "prior_probabilities = {'happy': 0.4, 'sad': 0.3, 'angry': 0.3}\n",
    "conditional_probabilities = {\n",
    "    'happy': {'happy': 0.25, 'joyful': 0.125, 'great': 0.125, 'sad': 0.05, 'down': 0.03, 'angry': 0.02, 'mad': 0.01, 'frustrated': 0.005},\n",
    "    'sad': {'happy': 0.05, 'joyful': 0.02, 'great': 0.03, 'sad': 0.20, 'down': 0.125, 'angry': 0.03, 'mad': 0.02, 'frustrated': 0.01},\n",
    "    'angry': {'happy': 0.10, 'joyful': 0.03, 'great': 0.02, 'sad': 0.05, 'down': 0.02, 'angry': 0.15, 'mad': 0.125, 'frustrated': 0.10}\n",
    "}\n",
    "\n",
    "# Function to preprocess the input text\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    return text.split()\n",
    "\n",
    "# Function to calculate P(E|W) for each emotion\n",
    "def calculate_posterior_probability(message):\n",
    "    words = preprocess_text(message)\n",
    "    \n",
    "    # Initialize posterior probabilities for each emotion\n",
    "    posterior_probabilities = {emotion: prior_probabilities[emotion] for emotion in emotions}\n",
    "    \n",
    "    # Calculate P(W|E) * P(E) for each emotion\n",
    "    for emotion in emotions:\n",
    "        for word in words:\n",
    "            # Handle words not found in conditional probabilities (assign a small probability)\n",
    "            if word in conditional_probabilities[emotion]:\n",
    "                posterior_probabilities[emotion] *= conditional_probabilities[emotion][word]\n",
    "            else:\n",
    "                posterior_probabilities[emotion] *= 0.001  # Small probability for unknown words\n",
    "    \n",
    "    # Calculate P(W)\n",
    "    total_prob = sum(posterior_probabilities.values())\n",
    "    \n",
    "    # Normalize the probabilities by dividing by P(W)\n",
    "    for emotion in emotions:\n",
    "        posterior_probabilities[emotion] /= total_prob\n",
    "    \n",
    "    # Return the emotion with the highest posterior probability\n",
    "    return max(posterior_probabilities, key=posterior_probabilities.get)\n",
    "\n",
    "# Example usage\n",
    "message = input(\"Enter a text message: \")\n",
    "predicted_emotion = calculate_posterior_probability(message)\n",
    "print(f\"The predicted emotion is: {predicted_emotion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140232c0-624a-45dd-b078-4713c7e83c90",
   "metadata": {},
   "source": [
    "### **Explanation of the Code:**\n",
    "\n",
    "**1. Preprocessing**: The preprocess_text() function removes punctuation from the input message and converts it to lowercase for consistency.\n",
    "\n",
    "**2. Bayes' Theorem Calculation**: The calculate_posterior_probability() function computes the posterior probability for each emotion based on the input message. It multiplies the prior probability of each emotion by the likelihood of each word in the message given that emotion. If a word is not in the conditional probabilities, a small probability is assumed.\n",
    "\n",
    "**3. Prediction**: The system predicts the most probable emotion by selecting the emotion with the highest posterior probability.\n",
    "\n",
    "### **Potential Error:**\n",
    "* **Unknown Words**: If the message contains many words not found in the training data, the probabilities may become too small to make a reliable prediction. To mitigate this, we assign a small probability for unknown words to prevent the system from producing zero probabilities for any emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764bf76d-3147-44ac-a88f-4537e70da1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
